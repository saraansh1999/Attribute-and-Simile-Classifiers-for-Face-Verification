Trait ->  Heavy Makeup
Train Data Shape ->  (2516, 500)
Positive samples ->  (1258,)
Negative samples ->  (1258,)
Fitting 2 folds for each of 4 candidates, totalling 8 fits
[CV] C=5, gamma=scale, kernel=rbf ....................................
[CV] ........ C=5, gamma=scale, kernel=rbf, score=0.797, total=   3.4s
[CV] C=5, gamma=scale, kernel=rbf ....................................
[CV] ........ C=5, gamma=scale, kernel=rbf, score=0.786, total=   3.3s
[CV] C=10, gamma=scale, kernel=rbf ...................................
[CV] ....... C=10, gamma=scale, kernel=rbf, score=0.798, total=   3.3s
[CV] C=10, gamma=scale, kernel=rbf ...................................
[CV] ....... C=10, gamma=scale, kernel=rbf, score=0.788, total=   3.2s
[CV] C=20, gamma=scale, kernel=rbf ...................................
[CV] ....... C=20, gamma=scale, kernel=rbf, score=0.808, total=   3.2s
[CV] C=20, gamma=scale, kernel=rbf ...................................
[CV] ....... C=20, gamma=scale, kernel=rbf, score=0.793, total=   3.2s
[CV] C=30, gamma=scale, kernel=rbf ...................................
[CV] ....... C=30, gamma=scale, kernel=rbf, score=0.805, total=   3.2s
[CV] C=30, gamma=scale, kernel=rbf ...................................
[CV] ....... C=30, gamma=scale, kernel=rbf, score=0.799, total=   3.2s
Best params:  SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',
    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
Train f1:  0.8019215311004786
Test Data Shape ->  (2830, 6600)
Confusion Matrix: 
 [[2068  476]
 [  56  230]]
              precision    recall  f1-score   support

       False       0.97      0.81      0.89      2544
        True       0.33      0.80      0.46       286

    accuracy                           0.81      2830
   macro avg       0.65      0.81      0.67      2830
weighted avg       0.91      0.81      0.84      2830

