Trait ->  Fully Visible Forehead
Train Data Shape ->  (6902, 500)
Positive samples ->  (3451,)
Negative samples ->  (3451,)
Fitting 2 folds for each of 4 candidates, totalling 8 fits
[CV] C=5, gamma=scale, kernel=rbf ....................................
[CV] ........ C=5, gamma=scale, kernel=rbf, score=0.763, total=  30.9s
[CV] C=5, gamma=scale, kernel=rbf ....................................
[CV] ........ C=5, gamma=scale, kernel=rbf, score=0.772, total=  30.9s
[CV] C=10, gamma=scale, kernel=rbf ...................................
[CV] ....... C=10, gamma=scale, kernel=rbf, score=0.761, total=  29.7s
[CV] C=10, gamma=scale, kernel=rbf ...................................
[CV] ....... C=10, gamma=scale, kernel=rbf, score=0.773, total=  29.1s
[CV] C=20, gamma=scale, kernel=rbf ...................................
[CV] ....... C=20, gamma=scale, kernel=rbf, score=0.763, total=  27.9s
[CV] C=20, gamma=scale, kernel=rbf ...................................
[CV] ....... C=20, gamma=scale, kernel=rbf, score=0.776, total=  27.3s
[CV] C=30, gamma=scale, kernel=rbf ...................................
[CV] ....... C=30, gamma=scale, kernel=rbf, score=0.760, total=  25.6s
[CV] C=30, gamma=scale, kernel=rbf ...................................
[CV] ....... C=30, gamma=scale, kernel=rbf, score=0.777, total=  23.6s
Best params:  SVC(C=20, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',
    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
Train f1:  0.7694908171358489
Test Data Shape ->  (2830, 6600)
Confusion Matrix: 
 [[ 581  266]
 [ 292 1691]]
              precision    recall  f1-score   support

       False       0.67      0.69      0.68       847
        True       0.86      0.85      0.86      1983

    accuracy                           0.80      2830
   macro avg       0.76      0.77      0.77      2830
weighted avg       0.80      0.80      0.80      2830

