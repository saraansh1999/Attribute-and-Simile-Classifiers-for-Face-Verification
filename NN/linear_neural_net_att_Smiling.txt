Trait -> Smiling
==> Options: Namespace(att_file='/scratch/saraansh/Attribute-and-Simile-Classifiers-for-Face-Verification/attr.pkl', batch_size=128, gamma=0.1, lr=0.001, model='linear', num_epochs=50, sample_thresh=0.75, save_path='/scratch/linear_neural_net_att_Smiling', step_size=12, test_dir='/scratch/saraansh/Attribute-and-Simile-Classifiers-for-Face-Verification/test_feat', testbatch_size=128, train_dir='/scratch/saraansh/Attribute-and-Simile-Classifiers-for-Face-Verification/train_feat', trait='Smiling', weight_decay=4e-05, workers=10)
Using GPU: True
train /scratch/saraansh/Attribute-and-Simile-Classifiers-for-Face-Verification/train_feat 9902
train Positive ->  4244
train Negative ->  5658
test /scratch/saraansh/Attribute-and-Simile-Classifiers-for-Face-Verification/test_feat 2830
test Positive ->  1188
test Negative ->  1642
NetBN(
  (features): Sequential(
    (0): Linear(in_features=6600, out_features=2048, bias=True)
    (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=2048, out_features=512, bias=True)
    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=512, out_features=64, bias=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): Linear(in_features=64, out_features=2, bias=True)
  )
)
Epoch 0/49
----------
==================================================================================
Train Loss:  tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 1/49
----------
==================================================================================
Train Loss:  tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 2/49
----------
==================================================================================
Train Loss:  tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 3/49
----------
==================================================================================
Train Loss:  tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 4/49
----------
==================================================================================
Train Loss:  tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 5/49
----------
==================================================================================
Train Loss:  tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 6/49
----------
==================================================================================
Train Loss:  tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 7/49
----------
==================================================================================
Train Loss:  tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 8/49
----------
==================================================================================
Train Loss:  tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 9/49
----------
==================================================================================
Train Loss:  tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 10/49
----------
==================================================================================
Train Loss:  tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 11/49
----------
==================================================================================
Train Loss:  tensor(0.0700, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 12/49
----------
==================================================================================
Train Loss:  tensor(0.0274, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 13/49
----------
==================================================================================
Train Loss:  tensor(0.0116, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 14/49
----------
==================================================================================
Train Loss:  tensor(0.0094, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 15/49
----------
==================================================================================
Train Loss:  tensor(0.0082, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 16/49
----------
==================================================================================
Train Loss:  tensor(0.0064, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 17/49
----------
==================================================================================
Train Loss:  tensor(0.0062, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 18/49
----------
==================================================================================
Train Loss:  tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 19/49
----------
==================================================================================
Train Loss:  tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 20/49
----------
==================================================================================
Train Loss:  tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 21/49
----------
==================================================================================
Train Loss:  tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 22/49
----------
==================================================================================
Train Loss:  tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 23/49
----------
==================================================================================
Train Loss:  tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 24/49
----------
==================================================================================
Train Loss:  tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 25/49
----------
==================================================================================
Train Loss:  tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 26/49
----------
==================================================================================
Train Loss:  tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 27/49
----------
==================================================================================
Train Loss:  tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 28/49
----------
==================================================================================
Train Loss:  tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 29/49
----------
==================================================================================
Train Loss:  tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 30/49
----------
==================================================================================
Train Loss:  tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 31/49
----------
==================================================================================
Train Loss:  tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 32/49
----------
==================================================================================
Train Loss:  tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 33/49
----------
==================================================================================
Train Loss:  tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 34/49
----------
==================================================================================
Train Loss:  tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 35/49
----------
==================================================================================
Train Loss:  tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 36/49
----------
==================================================================================
Train Loss:  tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 37/49
----------
==================================================================================
Train Loss:  tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 38/49
----------
==================================================================================
Train Loss:  tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 39/49
----------
==================================================================================
Train Loss:  tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 40/49
----------
==================================================================================
Train Loss:  tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 41/49
----------
==================================================================================
Train Loss:  tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 42/49
----------
==================================================================================
Train Loss:  tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 43/49
----------
==================================================================================
Train Loss:  tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 44/49
----------
==================================================================================
Train Loss:  tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 45/49
----------
==================================================================================
Train Loss:  tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 46/49
----------
==================================================================================
Train Loss:  tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 47/49
----------
==================================================================================
Train Loss:  tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 48/49
----------
==================================================================================
Train Loss:  tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)
Epoch 49/49
----------
==================================================================================
Train Loss:  tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)
==> Saving models ...
Creating Directory:  /scratch/linear_neural_net_att_Smiling/models
Confusion Matrix -> 
[[1414  228]
 [ 255  933]]
              precision    recall  f1-score   support

           0       0.85      0.86      0.85      1642
           1       0.80      0.79      0.79      1188

    accuracy                           0.83      2830
   macro avg       0.83      0.82      0.82      2830
weighted avg       0.83      0.83      0.83      2830

